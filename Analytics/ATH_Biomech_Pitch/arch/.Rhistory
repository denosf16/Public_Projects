source("scripts/train_model.R")
source("scripts/data_preprocessing.R")
df <- read.csv("outputs/pitch_data_cleaned.csv")
str(df$p_throws)  # Should return: Factor w/ 2 levels ("L", "R")
str(df$user)  # Should return: Factor w/ 100+ levels
source("scripts/data_preprocessing.R")
df <- read.csv("outputs/pitch_data_cleaned.csv", stringsAsFactors = TRUE)
str(df$p_throws)  # Must return: Factor w/ 2 levels ("L", "R")
str(df$user)  # Must return: Factor w/ 100+ levels
source("scripts/data_preprocessing.R")
df <- read.csv("outputs/pitch_data_cleaned.csv", stringsAsFactors = TRUE)
str(df$p_throws)  # Must return: Factor w/ 2 levels ("L", "R")
str(df$user)  # Must return: Factor w/ 100+ levels
source("scripts/data_preprocessing.R")
file.exists("pitch_meta.csv")
file.exists("pitch_poi.csv")
getwd()
source("scripts/data_preprocessing.R")
source("scripts/data_preprocessing.R")
source("scripts/data_preprocessing.R")
source("scripts/data_preprocessing.R")
source()
source("scripts/train_model.R")
source("scripts/predict.R")
# Load a model
test_model <- readRDS(FORCE_MODEL_FILE)
# Run posterior prediction with debugging
test_posterior <- posterior_predict(test_model, newdata = pitch_data_scaled)
# Print output dimensions
dim(test_posterior)  # Should be (samples, observations)
source("scripts/predict.R")
# Load the trained Force Model
force_model <- readRDS(FORCE_MODEL_FILE)
# Extract required features from the model
required_features <- attr(force_model$terms, "term.labels")
# Check features in `pitch_data_scaled`
actual_features <- colnames(pitch_data_scaled)
# Identify missing features
missing_features <- setdiff(required_features, actual_features)
# Print Debugging Information
print("üìå Features expected by the model:")
print(required_features)
print("üìå Features available in newdata:")
print(actual_features)
if (length(missing_features) > 0) {
print("‚ùå Missing Features in newdata:")
print(missing_features)
} else {
print("‚úÖ All required features are present!")
}
str(pitch_data_scaled[ , c("lead_grf_z_max", "rear_grf_z_max")])
source("scripts/predict.R")
source("scripts/model_evaluation.R")
colnames(read_csv("outputs/pitch_model_predictions.csv"))
source("scripts/model_evaluation.R")
source("scripts/constants.R")
source("scripts/helpers.R")
ls()  # List loaded objects
source("scripts/data_preprocessing.R")
source("scripts/data_preprocessing.R")
source("scripts/train_model.R")
source("scripts/predict.R")
source("scripts/model_evaluation.R")
source("scripts/data_preprocessing.R")
source("scripts/data_preprocessing.R")
source("scripts/feature_selection.R")
source("scripts/feature_selection.R")
source("scripts/train_model.R")
source("scripts/predict.R")
source("scripts/model_evaluation.R")
source("scripts/model_evaluation.R")
print(dim(predictions))  # Should show (rows, columns)
print(head(predictions)) # Preview the first few rows
print(colSums(is.na(predictions)))  # Check for missing values
if (!dir.exists(plots_dir)) {
dir.create(plots_dir, recursive = TRUE)
}
ggsave(filename = file.path(plots_dir, paste0(model_name, "_actual_vs_predicted.png")), plot = p1, width = 6, height = 5, dpi = 300)
plot_predictions <- function(predictions, model_name, model_column) {
# Scatter Plot: Actual vs. Predicted
p1 <- ggplot(predictions, aes(x = pitch_speed_mph, y = .data[[model_column]])) +
geom_point(alpha = 0.7, color = "blue") +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
labs(title = paste(model_name, "- Actual vs Predicted Pitch Speed"),
x = "Actual Pitch Speed (mph)", y = "Predicted Pitch Speed (mph)")
p1
print(p1)
plot_predictions(p1)
force_model <- stan_gamm4(
pitch_speed_mph ~ s(rear_grf_z_max) + lead_grf_z_max + p_throws + s(user, bs = "re"),
family = gaussian(),
data = scaled_pitch_data,
chains = 2, iter = 4000, warmup = 1500, adapt_delta = 0.95,
control = list(max_treedepth = 12), cores = 2
)
saveRDS(force_model, FORCE_MODEL_FILE)
flog.info("‚úÖ Force Model saved.")
force_model <- stan_gamm4(
pitch_speed_mph ~ s(rear_grf_z_max) + lead_grf_z_max + p_throws + s(user, bs = "re"),
family = gaussian(),
data = scaled_pitch_data,
chains = 2, iter = 4000, warmup = 1500, adapt_delta = 0.95,
control = list(max_treedepth = 12), cores = 2
)
saveRDS(force_model, FORCE_MODEL_FILE)
flog.info("‚úÖ Force Model saved.")
)
force_model <- stan_gamm4(
pitch_speed_mph ~ s(rear_grf_z_max) + lead_grf_z_max + p_throws + s(user, bs = "re"),
family = gaussian(),
data = scaled_pitch_data,
chains = 2, iter = 4000, warmup = 1500, adapt_delta = 0.95,
control = list(max_treedepth = 12), cores = 2
)
knitr::opts_chunk$set(echo = TRUE)
force_model <- stan_gamm4(
pitch_speed_mph ~ s(rear_grf_z_max) + lead_grf_z_max +
p_throws + s(user, bs = "re"),  # Corrected random effect
family = gaussian(),
data = scaled_pitch_data,
chains = 2,
iter = 4000,
warmup = 1500,
adapt_delta = 0.95,
control = list(max_treedepth = 12),
cores = 2
)
View(scaled_pitch_data)
print(colSums(is.na(scaled_pitch_data)))
print(colSums(is.na(cleaned_data)))
knitr::opts_chunk$set(echo = TRUE)
# Load required libraries
options(mc.cores = parallel::detectCores())
library(rstanarm)
library(moments)
library(ggplot2)
library(reshape2)
library(corrplot)
library(naniar)
library(missRanger)
library(VIM)
library(dplyr)
library(factoextra)
library(stringr)
library(cluster)
library(dendextend)
library(patchwork)
library(moments)
library(randomForest)
library(minerva)
library(Hmisc)
library(knitr)
library(kableExtra)
library(car)
# Define file paths
meta_url <- "https://raw.githubusercontent.com/drivelineresearch/openbiomechanics/main/baseball_pitching/data/metadata.csv"
poi_url <- "https://raw.githubusercontent.com/drivelineresearch/openbiomechanics/main/baseball_pitching/data/poi/poi_metrics.csv"
# Download files to a temporary location
download.file(meta_url, destfile = "pitch_meta.csv", method = "libcurl")
download.file(poi_url, destfile = "pitch_poi.csv", method = "libcurl")
# Read the downloaded CSVs
pitch_meta <- read.csv("pitch_meta.csv")
pitch_poi <- read.csv("pitch_poi.csv")
# Select relevant columns from pitch_meta
pitch_meta_selected <- pitch_meta %>%
select(session_pitch, user, session_mass_kg, session_height_m, age_yrs, playing_level)
# Perform a left join to retain all data from pitch_poi
pitch_data <- pitch_poi %>%
left_join(pitch_meta_selected, by = "session_pitch")
# View the first few rows of the joined dataset
head(pitch_data)
data_types_p <- data.frame(
Variable = names(pitch_data),
Data_Type = sapply(pitch_data, class)
)
# Count missing values for each column
missing_values_p <- colSums(is.na(pitch_data))
# Filter and list columns with NA > 0
columns_with_na_p <- missing_values_p[missing_values_p > 0]
# Display the result
print("Columns with missing values:")
print(columns_with_na_p)
# Perform Random Forest Imputation using missRanger
pitch_data_imp <- missRanger(pitch_data,
pmm.k = 3,  # Predictive mean matching for better realism
num.trees = 100,  # Number of trees in the Random Forest
seed = 123,  # For reproducibility
verbose = 2) # Print progress
sum(is.na(pitch_data_imp))
# List of columns that were imputed
imputed_columns <- c("lead_hip_transfer_fp_br", "lead_hip_generation_fp_br",
"lead_hip_absorption_fp_br", "lead_knee_transfer_fp_br",
"lead_knee_generation_fp_br", "lead_knee_absorption_fp_br",
"rear_hip_transfer_pkh_fp", "rear_hip_generation_pkh_fp",
"rear_hip_absorption_pkh_fp", "rear_knee_transfer_pkh_fp",
"rear_knee_generation_pkh_fp", "rear_knee_absorption_pkh_fp",
"pelvis_lumbar_transfer_fp_br", "rear_grf_x_max", "rear_grf_y_max",
"rear_grf_z_max", "rear_grf_mag_max", "rear_grf_angle_at_max",
"lead_grf_x_max", "lead_grf_y_max", "lead_grf_z_max",
"lead_grf_mag_max", "lead_grf_angle_at_max", "peak_rfd_rear",
"peak_rfd_lead")
# Create a copy of the dataset *before* imputation (Assuming `pitch_data` is the original dataset)
pitch_data_before_imputation <- pitch_data  # Replace with actual pre-imputation dataset if needed
# Create 'imputed_flag' column: Flag only the 8 rows that had missing values before imputation
pitch_data_imp <- pitch_data_imp %>%
mutate(imputed_flag = ifelse(rowSums(is.na(select(pitch_data_before_imputation, all_of(imputed_columns)))) > 0, 1, 0))
# Confirm that only 8 rows are flagged
table(pitch_data_imp$imputed_flag)
### ---- Generate Histograms for Imputed Columns ---- ###
for (col in imputed_columns) {
p <- ggplot(pitch_data_imp, aes_string(x = col)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black", alpha = 0.7) +
theme_minimal() +
labs(title = paste("Histogram of", col), x = col, y = "Count") +
theme(plot.title = element_text(hjust = 0.5))
print(p)  # Display each histogram
}
for (col in imputed_columns) {
p2 <- ggplot(pitch_data_imp, aes_string(x = col, y = "pitch_speed_mph", color = "as.factor(imputed_flag)")) +
geom_point(alpha = 0.7, size = 1) +
theme_minimal() +
scale_color_manual(values = c("blue", "red"), labels = c("Not Imputed", "Imputed")) +
labs(title = paste("Pitch Speed vs", col), x = col, y = "Pitch Speed (mph)", color = "Imputed Data") +
theme(plot.title = element_text(hjust = 0.5))
print(p2)  # Display each scatterplot
}
# Step 1: Check normality using Shapiro-Wilk test
normality_results <- sapply(select(pitch_data_imp, where(is.numeric)), function(x) {
if (length(na.omit(x)) > 3) {  # Ensure enough data for the test
return(shapiro.test(na.omit(x))$p.value)
} else {
return(NA)
}
})
# Convert to a data frame
normality_results_df <- data.frame(Variable = names(normality_results),
P_Value = normality_results)
# Classify variables as normal (TRUE) or non-normal (FALSE)
normality_results_df <- normality_results_df %>%
mutate(Normal_Distribution = ifelse(P_Value > 0.05, TRUE, FALSE))
# Step 2: Define Outlier Detection Functions
# Function to detect Z-score outliers (for normal distributions)
detect_z_outliers <- function(x) {
z_scores <- (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
return(abs(z_scores) > 3)
}
# Function to detect IQR outliers (for non-normal distributions)
detect_iqr_outliers <- function(x) {
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr_value <- q3 - q1
return(x < (q1 - 1.5 * iqr_value) | x > (q3 + 1.5 * iqr_value))
}
# Step 3: Apply appropriate outlier detection method based on normality results
pitch_data_imp <- pitch_data_imp %>%
mutate(across(where(is.numeric), ~ ifelse(
coalesce(normality_results_df$Normal_Distribution[match(cur_column(), normality_results_df$Variable)], FALSE),
detect_z_outliers(.),
detect_iqr_outliers(.)
), .names = "{.col}_outlier"))
# Step 4: Count number of outliers detected per column
outlier_counts <- colSums(select(pitch_data_imp, ends_with("_outlier")), na.rm = TRUE)
print("üö® Outlier Counts Per Variable üö®")
print(outlier_counts)
# Step 5: Filter and inspect rows with any outliers
outlier_rows <- pitch_data_imp %>%
filter(if_any(ends_with("_outlier"), ~ . == TRUE))
print("üö® Outlier Rows Detected üö®")
print(outlier_rows)
# üîπ **Select Only Numeric Columns**
numeric_data <- pitch_data_imp %>% select(where(is.numeric))
# üîπ **Compute Correlation Matrix**
cor_matrix <- cor(numeric_data, use = "complete.obs")
# üîπ **Set Correlation Threshold & Extract Highly Correlated Variables**
cor_threshold <- 0.2  # Adjust as needed
# Get variables highly correlated with pitch_speed_mph
high_corr_vars_pitch_speed <- rownames(cor_matrix)[cor_matrix["pitch_speed_mph", ] > cor_threshold |
cor_matrix["pitch_speed_mph", ] < -cor_threshold]
# üîπ **Generate Heatmap Only if Correlated Variables Exist**
if (length(high_corr_vars_pitch_speed) > 1) {
corrplot(cor_matrix[high_corr_vars_pitch_speed, high_corr_vars_pitch_speed],
method = "color", tl.cex = 0.8, title = "Correlation Heatmap - Pitch Speed")
}
# üîπ **Exclude Unwanted Variables**
exclude_vars <- c("session", "user", "session_mass_kg", "session_height_m", "age_yrs")  # Adjust as needed
# üîπ **Remove Excluded Variables from High-Correlation Predictor Lists**
if (exists("high_corr_vars_pitch_speed")) {
high_corr_vars_pitch_speed <- setdiff(high_corr_vars_pitch_speed, exclude_vars)
} else {
high_corr_vars_pitch_speed <- character(0)  # Avoids NULL errors
}
# üîπ **Train Random Forest Model for Pitch Speed**
if (length(high_corr_vars_pitch_speed) > 1) {
rf_pitch_speed <- randomForest(
pitch_speed_mph ~ .,
data = na.omit(pitch_data_imp %>% select(pitch_speed_mph, all_of(high_corr_vars_pitch_speed))),
importance = TRUE, ntree = 2500
)
# Extract Feature Importance
importance_pitch_speed <- importance(rf_pitch_speed)
importance_pitch_speed_df <- data.frame(
Variable = rownames(importance_pitch_speed),
Importance = importance_pitch_speed[, "IncNodePurity"]
)
# üîπ **Ensure importance values exist before plotting**
if (nrow(importance_pitch_speed_df) > 0 && sum(importance_pitch_speed_df$Importance) > 0) {
print("üîç Feature Importance for Pitch Speed:")
print(importance_pitch_speed_df)  # Debugging
# üîπ **Plot feature importance**
p_pitch_speed <- ggplot(importance_pitch_speed_df, aes(x = reorder(Variable, Importance), y = Importance)) +
geom_bar(stat = "identity", fill = "blue") +
coord_flip() +
labs(title = "Feature Importance - Pitch Speed",
x = "Variable",
y = "Importance (IncNodePurity)") +
theme_minimal()
print(p_pitch_speed)  # Force ggplot to render
}
}
# Remove pitch_speed_mph from the predictor list (if it exists)
high_corr_vars_pitch_speed <- setdiff(high_corr_vars_pitch_speed, "pitch_speed_mph")
# Compute MIC for pitch speed using high-correlation variables (excluding pitch_speed_mph)
mic_results_pitch_speed <- apply(pitch_data_imp %>% select(all_of(high_corr_vars_pitch_speed)), 2, function(x) {
mine(x, pitch_data_imp$pitch_speed_mph)$MIC
})
# Convert MIC results to a dataframe
mic_pitch_speed_df <- data.frame(Variable = names(mic_results_pitch_speed), MIC = mic_results_pitch_speed)
# Plot MIC results
ggplot(mic_pitch_speed_df, aes(x = reorder(Variable, MIC), y = MIC)) +
geom_bar(stat = "identity", fill = "blue") +
coord_flip() +
labs(title = "MIC Score - Pitch Speed (Excluding Itself)",
x = "Variable",
y = "MIC Score") +
theme_minimal()
# üîπ Ensure predictor variables do not include the target variable
high_corr_vars_pitch_speed <- setdiff(high_corr_vars_pitch_speed, "pitch_speed_mph")
# Loop through each predictor and generate scatterplots
for (var in high_corr_vars_pitch_speed) {
p <- ggplot(pitch_data_imp, aes_string(x = var, y = "pitch_speed_mph")) +
geom_point(alpha = 0.6, color = "blue") +  # Scatterplot points
geom_smooth(method = "loess", color = "red", se = FALSE, linetype = "solid") +  # LOESS trendline
geom_smooth(method = "lm", color = "black", se = FALSE, linetype = "dashed") +  # Linear regression trendline
labs(title = paste("Scatterplot of", var, "vs Pitch Speed"),
x = var,
y = "Pitch Speed (mph)") +
theme_minimal()
print(p)  # Display the plot
}
# Define predictor variables (excluding the response variable)
pitch_speed_predictors <- setdiff(high_corr_vars_pitch_speed, "pitch_speed_mph")
# Compute MIC for Predictor-Predictor Relationships
mic_pitch_speed <- mine(na.omit(pitch_data_imp %>% select(all_of(pitch_speed_predictors))))$MIC
# Compute Pearson Correlation for Predictor-Predictor Relationships
pearson_pitch_speed <- rcorr(as.matrix(na.omit(pitch_data_imp %>% select(all_of(pitch_speed_predictors)))))$r
# Convert MIC & Pearson Matrices to DataFrames
convert_to_df <- function(mic_matrix, pearson_matrix) {
mic_df <- as.data.frame(as.table(mic_matrix)) %>% rename(Var1 = Var1, Var2 = Var2, MIC = Freq)
pearson_df <- as.data.frame(as.table(pearson_matrix)) %>% rename(Var1 = Var1, Var2 = Var2, Pearson = Freq)
left_join(mic_df, pearson_df, by = c("Var1", "Var2"))
}
pitch_speed_results <- convert_to_df(mic_pitch_speed, pearson_pitch_speed)
# Function to compute MIC & Pearson correlation between predictors and the response variable
compute_response_relationship <- function(predictors, response_var) {
results <- lapply(predictors, function(var) {
# Compute MIC only between the predictor and the response
mic_value <- mine(na.omit(pitch_data_imp %>% select(all_of(c(var, response_var)))))$MIC[1, 2]
# Compute Pearson correlation between predictor and response
pearson_value <- cor(pitch_data_imp[[var]], pitch_data_imp[[response_var]], use = "complete.obs")
# Return a formatted row
data.frame(Var1 = var, MIC = round(mic_value, 3), Pearson = round(pearson_value, 3))
})
# Combine results and filter for nonlinear relationships
df <- bind_rows(results) %>%
filter(MIC >= 0.2 & abs(Pearson) <= 0.4)  # Select nonlinear candidates
return(df)
}
# Compute Response-Predictor Relationships for Nonlinear Terms
pitch_speed_nonlinear <- compute_response_relationship(pitch_speed_predictors, "pitch_speed_mph")
# Filter Predictor-Predictor Relationships for Interaction & Multicollinearity
pitch_speed_interactions <- pitch_speed_results %>%
filter(MIC >= 0.2 & MIC <= 0.5 | MIC <= 0.6) %>%
filter(Pearson >= 0.4 & Pearson <= 0.6) %>%
filter(Var1 != Var2)  # Selecting interaction term candidates
pitch_speed_multicollinear <- pitch_speed_results %>%
filter(abs(Pearson) >= 0.7) %>%
filter(Var1 != Var2)  # Selecting multicollinear variable pairs
# Function to Remove Self-Correlations & Duplicate Pairs
remove_duplicate_pairs <- function(df) {
df %>%
mutate(
Var1 = as.character(Var1),
Var2 = as.character(Var2),
Var_low = ifelse(Var1 < Var2, Var1, Var2),
Var_high = ifelse(Var1 < Var2, Var2, Var1)
) %>%
filter(Var_low != Var_high) %>%  # Remove self-correlations
distinct(Var_low, Var_high, .keep_all = TRUE) %>%  # Keep only unique pairs
select(-Var1, -Var2) %>%  # Drop old columns
rename(Var1 = Var_low, Var2 = Var_high) %>%  # Rename back
select(Var1, Var2, MIC, Pearson)  # Reorder columns
}
# Apply duplicate removal
pitch_speed_interactions <- remove_duplicate_pairs(pitch_speed_interactions)
pitch_speed_multicollinear <- remove_duplicate_pairs(pitch_speed_multicollinear)
# Function to Display Tables
display_table <- function(df, title) {
if (nrow(df) > 0) {
df %>%
kable("html", caption = title) %>%
kable_styling(full_width = FALSE, position = "center", bootstrap_options = c("striped", "hover"))
} else {
cat(paste("‚ö†Ô∏è No significant", title, "found.\n"))
}
}
# Display Tables
display_table(pitch_speed_interactions, "Pitch Speed Interaction Candidates")
display_table(pitch_speed_nonlinear, "Pitch Speed Nonlinear Term Candidates")
display_table(pitch_speed_multicollinear, "Pitch Speed Multicollinear Variables")
final_vars <- c(
"max_shoulder_internal_rotational_velo", "max_shoulder_external_rotation", "max_shoulder_horizontal_abduction",
"elbow_varus_moment", "elbow_transfer_fp_br",
"max_torso_rotational_velo", "max_rotation_hip_shoulder_separation", "pelvis_anterior_tilt_fp",
"max_cog_velo_x", "lead_knee_extension_from_fp_to_br", "lead_knee_transfer_fp_br",
"rear_hip_generation_pkh_fp", "rear_grf_z_max", "lead_grf_z_max"
)
# Run VIF test
vif_data <- lm(pitch_speed_mph ~ ., data = pitch_data_imp %>% select(pitch_speed_mph, all_of(final_vars)))
vif_results <- vif(vif_data)
# Print VIF results
print(vif_results)
# Scale numeric predictors only (excluding categorical variables)
# Ensure categorical variables are correctly treated
scaled_pitch_data <- pitch_data_imp %>%
mutate(across(where(is.numeric), ~ scale(.)[,1])) %>%
mutate(
p_throws = as.factor(p_throws),
user = as.factor(user)  # User must be a factor for random effects
)
# Load required libraries
options(mc.cores = 2)  # Reduce parallel processing
# üîπ 1Ô∏è‚É£ Force Model (GRF)
force_model <- stan_gamm4(
pitch_speed_mph ~ s(rear_grf_z_max) + lead_grf_z_max +
p_throws + s(user, bs = "re"),  # Corrected random effect
family = gaussian(),
data = scaled_pitch_data,
chains = 2,
iter = 4000,
warmup = 1500,
adapt_delta = 0.95,
control = list(max_treedepth = 12),
cores = 2
)
return(list(p1 = p1, p2 = p2))  # Return plots for debugging if needed
source("scripts/model_evaluation.R")
p1
return(p1)
print(p1)
install.packages("bslib")
install.packages("bslib")
bslib::bs_theme_preview()
install.packages("bsicons")
bslib::bs_theme_preview()
bslib::bs_theme_preview()
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
library(naniar)
vis_miss(h_rf_imputed)
list.files("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/", recursive = TRUE, full.names = TRUE, pattern = "hitter_combined_cleaned.csv
list.files("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/", recursive = TRUE, full.names = TRUE, pattern = "hitter_combined_cleaned.csv"
list.files("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/", recursive = TRUE, full.names = TRUE, pattern = "hitter_combined_cleaned.csv")
ls()
str(hitter_combined)  # Check structure
head(hitter_combined) # Preview first few rows
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
colSums(is.na(h_rf_imputed))
str(h_rf_imputed)
# üîÑ Run Constants, Helpers, and Data Preprocessing Scripts
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
dir.exists("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/data")
# üîÑ Run Constants, Helpers, and Data Preprocessing Scripts
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
print(SESSION_KEY)  # This should return "session_swing"
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/constants.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/helpers.R")
source("C:/Repos/Athlyticz_Projects/ATH_Biomech_Hit/Model/scripts/data_preprocessing.R")
